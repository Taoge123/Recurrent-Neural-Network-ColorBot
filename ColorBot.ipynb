{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested with TensorFlow 1.2.0\n",
      "Your TensorFlow version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "print('Tested with TensorFlow 1.2.0')\n",
    "print('Your TensorFlow version:', tf.__version__) \n",
    "\n",
    "# Feeding function for enqueue data\n",
    "from tensorflow.python.estimator.inputs.queues import feeding_functions as ff\n",
    "\n",
    "# Rnn common functions\n",
    "from tensorflow.contrib.learn.python.learn.estimators import rnn_common\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "# Model builder\n",
    "from tensorflow.python.estimator import model_fn as model_fn_lib\n",
    "\n",
    "# Plot images with pyplot\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Helpers for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data files\n",
    "TRAIN_INPUT = 'data/train.csv'\n",
    "TEST_INPUT = 'data/test.csv'\n",
    "MY_TEST_INPUT = 'data/mytest.csv'\n",
    "\n",
    "# Parameters for training\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Parameters for data processing\n",
    "VOCAB_SIZE = 256\n",
    "CHARACTERS = [chr(i) for i in range(VOCAB_SIZE)]\n",
    "SEQUENCE_LENGTH_KEY = 'sequence_length'\n",
    "COLOR_NAME_KEY = 'color_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the column values from a CSV file as a list\n",
    "def _get_csv_column(csv_file, column_name):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        return df[column_name].tolist()\n",
    "\n",
    "# Plots a color image\n",
    "def _plot_rgb(rgb):\n",
    "    data = [[rgb]]\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(data, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(csv_file, batch_size, num_epochs=1, shuffle=True):\n",
    "    def _parse(line):\n",
    "        # each line: name, red, green, blue\n",
    "        # split line\n",
    "        items = tf.string_split([line],',').values\n",
    "\n",
    "        # get color (r, g, b)\n",
    "        color = tf.string_to_number(items[1:], out_type=tf.float32) / 255.0\n",
    "\n",
    "        # split color_name into a sequence of characters\n",
    "        color_name = tf.string_split([items[0]], '')\n",
    "        length = color_name.indices[-1, 1] + 1 # length = index of last char + 1\n",
    "        color_name = color_name.values\n",
    "        \n",
    "        return color, color_name, length\n",
    "\n",
    "    def _length_bin(length, cast_value=5, max_bin_id=10):\n",
    "        '''\n",
    "        Chooses a bin for a word given it's length.\n",
    "        The goal is to use group_by_window to group words\n",
    "        with the ~ same ~ length in the same bin.\n",
    "\n",
    "        Each bin will have the size of a batch, so it can train faster.\n",
    "        '''\n",
    "        bin_id = tf.cast(length / cast_value, dtype=tf.int64)\n",
    "        return tf.minimum(bin_id, max_bin_id)\n",
    "\n",
    "    def _pad_batch(ds, batch_size):\n",
    "        return ds.padded_batch(batch_size, \n",
    "                               padded_shapes=([None], [None], []),\n",
    "                               padding_values=(0.0, chr(0), tf.cast(0, tf.int64)))\n",
    "\n",
    "    def input_fn():\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(csv_file) # reading from the HD\n",
    "            .skip(1) # skip header\n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "            .map(_parse) # parse text to variables\n",
    "            .group_by_window(key_func=lambda color, color_name, length: _length_bin(length), # choose a bin\n",
    "                             reduce_func=lambda key, ds: _pad_batch(ds, batch_size), # apply reduce funtion\n",
    "                             window_size=batch_size)\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        color, color_name, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            COLOR_NAME_KEY: color_name,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, color\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE)\n",
    "test_input_fn = get_input_fn(TEST_INPUT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color_name': array([[b'b', b'l', b'o', b'o', b'd', b' ', b'r', b'e', b'd']], dtype=object), 'sequence_length': array([9])}\n",
      "[[ 0.37254903  0.61960787  0.627451  ]]\n"
     ]
    }
   ],
   "source": [
    "x, y = get_input_fn(TRAIN_INPUT, 1)()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    print(s.run(x))\n",
    "    print(s.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        color_name = features[COLOR_NAME_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], dtype=tf.int32) # int64 -> int32\n",
    "        \n",
    "        # ----------- Preparing input --------------------\n",
    "        # Creating a tf constant to hold the map char -> index\n",
    "        mapping = tf.constant(CHARACTERS, name=\"mapping\")\n",
    "        table = tf.contrib.lookup.index_table_from_tensor(mapping, dtype=tf.string)\n",
    "        int_color_name = table.lookup(color_name)\n",
    "        \n",
    "        # converting color names to one hot representation\n",
    "        color_name_onehot = tf.one_hot(int_color_name, depth=len(CHARACTERS) + 1)\n",
    "        \n",
    "        # ---------- RNN -------------------\n",
    "        # Each RNN layer will consist of a LSTM cell\n",
    "        rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=color_name_onehot,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # ------------ Dense layers -------------------\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "\n",
    "        # ----------- Loss and Optimizer ----------------\n",
    "        loss = None\n",
    "        train_op = None\n",
    "\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:    \n",
    "            loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                           predictions=predictions,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'colorbot', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "model_fn = get_model_fn(rnn_cell_sizes=[256, 128], # size of the hidden layers\n",
    "                        label_dimension=3, # since is RGB\n",
    "                        dnn_layer_sizes=[128], # size of units in the dense layers on top of the RNN\n",
    "                        optimizer='Adam', # changing optimizer to Adam\n",
    "                        learning_rate=0.01)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir='colorbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4572\n",
      "INFO:tensorflow:Saving checkpoints for 4573 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00568408, step = 4573\n",
      "INFO:tensorflow:Saving checkpoints for 4595 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00526464.\n",
      "Evaluating epoch 0\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:55:42\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4595\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:55:43\n",
      "INFO:tensorflow:Saving dict for global step 4595: global_step = 4595, loss = 0.0534455\n",
      "Training epoch 1\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4595\n",
      "INFO:tensorflow:Saving checkpoints for 4596 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00846301, step = 4596\n",
      "INFO:tensorflow:Saving checkpoints for 4618 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00164088.\n",
      "Evaluating epoch 1\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:56:07\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4618\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:56:08\n",
      "INFO:tensorflow:Saving dict for global step 4618: global_step = 4618, loss = 0.0480564\n",
      "Training epoch 2\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4618\n",
      "INFO:tensorflow:Saving checkpoints for 4619 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00449429, step = 4619\n",
      "INFO:tensorflow:Saving checkpoints for 4641 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00657812.\n",
      "Evaluating epoch 2\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:56:30\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4641\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:56:32\n",
      "INFO:tensorflow:Saving dict for global step 4641: global_step = 4641, loss = 0.057724\n",
      "Training epoch 3\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4641\n",
      "INFO:tensorflow:Saving checkpoints for 4642 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00708506, step = 4642\n",
      "INFO:tensorflow:Saving checkpoints for 4664 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00745684.\n",
      "Evaluating epoch 3\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:56:57\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4664\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:56:58\n",
      "INFO:tensorflow:Saving dict for global step 4664: global_step = 4664, loss = 0.0572944\n",
      "Training epoch 4\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4664\n",
      "INFO:tensorflow:Saving checkpoints for 4665 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00621249, step = 4665\n",
      "INFO:tensorflow:Saving checkpoints for 4687 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00107985.\n",
      "Evaluating epoch 4\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:57:17\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4687\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:57:18\n",
      "INFO:tensorflow:Saving dict for global step 4687: global_step = 4687, loss = 0.0490759\n",
      "Training epoch 5\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4687\n",
      "INFO:tensorflow:Saving checkpoints for 4688 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00486253, step = 4688\n",
      "INFO:tensorflow:Saving checkpoints for 4710 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00401883.\n",
      "Evaluating epoch 5\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:57:38\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4710\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:57:39\n",
      "INFO:tensorflow:Saving dict for global step 4710: global_step = 4710, loss = 0.0475075\n",
      "Training epoch 6\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4710\n",
      "INFO:tensorflow:Saving checkpoints for 4711 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00547147, step = 4711\n",
      "INFO:tensorflow:Saving checkpoints for 4733 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000644135.\n",
      "Evaluating epoch 6\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:57:56\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4733\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:57:57\n",
      "INFO:tensorflow:Saving dict for global step 4733: global_step = 4733, loss = 0.0610116\n",
      "Training epoch 7\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4733\n",
      "INFO:tensorflow:Saving checkpoints for 4734 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00596635, step = 4734\n",
      "INFO:tensorflow:Saving checkpoints for 4756 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00289261.\n",
      "Evaluating epoch 7\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:58:16\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4756\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:58:17\n",
      "INFO:tensorflow:Saving dict for global step 4756: global_step = 4756, loss = 0.0500253\n",
      "Training epoch 8\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4756\n",
      "INFO:tensorflow:Saving checkpoints for 4757 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00262899, step = 4757\n",
      "INFO:tensorflow:Saving checkpoints for 4779 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00166964.\n",
      "Evaluating epoch 8\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:58:34\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4779\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:58:35\n",
      "INFO:tensorflow:Saving dict for global step 4779: global_step = 4779, loss = 0.0500235\n",
      "Training epoch 9\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4779\n",
      "INFO:tensorflow:Saving checkpoints for 4780 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00361592, step = 4780\n",
      "INFO:tensorflow:Saving checkpoints for 4802 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000324857.\n",
      "Evaluating epoch 9\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:58:55\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4802\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:58:56\n",
      "INFO:tensorflow:Saving dict for global step 4802: global_step = 4802, loss = 0.046885\n",
      "Training epoch 10\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4802\n",
      "INFO:tensorflow:Saving checkpoints for 4803 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00274447, step = 4803\n",
      "INFO:tensorflow:Saving checkpoints for 4825 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0019125.\n",
      "Evaluating epoch 10\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:59:14\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4825\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:59:16\n",
      "INFO:tensorflow:Saving dict for global step 4825: global_step = 4825, loss = 0.0469004\n",
      "Training epoch 11\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4825\n",
      "INFO:tensorflow:Saving checkpoints for 4826 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00223135, step = 4826\n",
      "INFO:tensorflow:Saving checkpoints for 4848 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000991648.\n",
      "Evaluating epoch 11\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-17:59:35\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4848\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-17:59:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4848: global_step = 4848, loss = 0.0448706\n",
      "Training epoch 12\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4848\n",
      "INFO:tensorflow:Saving checkpoints for 4849 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00283283, step = 4849\n",
      "INFO:tensorflow:Saving checkpoints for 4871 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000136655.\n",
      "Evaluating epoch 12\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:00:00\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4871\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:00:01\n",
      "INFO:tensorflow:Saving dict for global step 4871: global_step = 4871, loss = 0.0438762\n",
      "Training epoch 13\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4871\n",
      "INFO:tensorflow:Saving checkpoints for 4872 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00344502, step = 4872\n",
      "INFO:tensorflow:Saving checkpoints for 4894 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00196139.\n",
      "Evaluating epoch 13\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:00:26\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4894\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:00:27\n",
      "INFO:tensorflow:Saving dict for global step 4894: global_step = 4894, loss = 0.0478791\n",
      "Training epoch 14\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4894\n",
      "INFO:tensorflow:Saving checkpoints for 4895 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00109318, step = 4895\n",
      "INFO:tensorflow:Saving checkpoints for 4917 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0019266.\n",
      "Evaluating epoch 14\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:00:46\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4917\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:00:47\n",
      "INFO:tensorflow:Saving dict for global step 4917: global_step = 4917, loss = 0.0594008\n",
      "Training epoch 15\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4917\n",
      "INFO:tensorflow:Saving checkpoints for 4918 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00426481, step = 4918\n",
      "INFO:tensorflow:Saving checkpoints for 4940 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00134059.\n",
      "Evaluating epoch 15\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:01:06\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4940\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:01:07\n",
      "INFO:tensorflow:Saving dict for global step 4940: global_step = 4940, loss = 0.0566626\n",
      "Training epoch 16\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4940\n",
      "INFO:tensorflow:Saving checkpoints for 4941 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00297819, step = 4941\n",
      "INFO:tensorflow:Saving checkpoints for 4963 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0014033.\n",
      "Evaluating epoch 16\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:01:27\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4963\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:01:28\n",
      "INFO:tensorflow:Saving dict for global step 4963: global_step = 4963, loss = 0.0468664\n",
      "Training epoch 17\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4963\n",
      "INFO:tensorflow:Saving checkpoints for 4964 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00252394, step = 4964\n",
      "INFO:tensorflow:Saving checkpoints for 4986 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0027787.\n",
      "Evaluating epoch 17\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:01:46\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4986\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:01:47\n",
      "INFO:tensorflow:Saving dict for global step 4986: global_step = 4986, loss = 0.0437434\n",
      "Training epoch 18\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-4986\n",
      "INFO:tensorflow:Saving checkpoints for 4987 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00549971, step = 4987\n",
      "INFO:tensorflow:Saving checkpoints for 5009 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000789593.\n",
      "Evaluating epoch 18\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:02:07\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5009\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:02:08\n",
      "INFO:tensorflow:Saving dict for global step 5009: global_step = 5009, loss = 0.0529409\n",
      "Training epoch 19\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5009\n",
      "INFO:tensorflow:Saving checkpoints for 5010 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00838311, step = 5010\n",
      "INFO:tensorflow:Saving checkpoints for 5032 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00572641.\n",
      "Evaluating epoch 19\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:02:25\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5032\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:02:26\n",
      "INFO:tensorflow:Saving dict for global step 5032: global_step = 5032, loss = 0.0503056\n",
      "Training epoch 20\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5032\n",
      "INFO:tensorflow:Saving checkpoints for 5033 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00355422, step = 5033\n",
      "INFO:tensorflow:Saving checkpoints for 5055 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00211802.\n",
      "Evaluating epoch 20\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:02:43\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5055\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:02:44\n",
      "INFO:tensorflow:Saving dict for global step 5055: global_step = 5055, loss = 0.0557167\n",
      "Training epoch 21\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5055\n",
      "INFO:tensorflow:Saving checkpoints for 5056 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00568011, step = 5056\n",
      "INFO:tensorflow:Saving checkpoints for 5078 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00363047.\n",
      "Evaluating epoch 21\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:03:01\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5078\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:03:02\n",
      "INFO:tensorflow:Saving dict for global step 5078: global_step = 5078, loss = 0.0582063\n",
      "Training epoch 22\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5078\n",
      "INFO:tensorflow:Saving checkpoints for 5079 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00616115, step = 5079\n",
      "INFO:tensorflow:Saving checkpoints for 5101 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00655274.\n",
      "Evaluating epoch 22\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:03:19\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5101\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:03:20\n",
      "INFO:tensorflow:Saving dict for global step 5101: global_step = 5101, loss = 0.0556691\n",
      "Training epoch 23\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5101\n",
      "INFO:tensorflow:Saving checkpoints for 5102 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00895727, step = 5102\n",
      "INFO:tensorflow:Saving checkpoints for 5124 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00126677.\n",
      "Evaluating epoch 23\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:03:36\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5124\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:03:37\n",
      "INFO:tensorflow:Saving dict for global step 5124: global_step = 5124, loss = 0.0583523\n",
      "Training epoch 24\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5124\n",
      "INFO:tensorflow:Saving checkpoints for 5125 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00746646, step = 5125\n",
      "INFO:tensorflow:Saving checkpoints for 5147 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00400408.\n",
      "Evaluating epoch 24\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:03:54\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5147\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:03:55\n",
      "INFO:tensorflow:Saving dict for global step 5147: global_step = 5147, loss = 0.0515888\n",
      "Training epoch 25\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5147\n",
      "INFO:tensorflow:Saving checkpoints for 5148 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00648354, step = 5148\n",
      "INFO:tensorflow:Saving checkpoints for 5170 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000477466.\n",
      "Evaluating epoch 25\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:04:15\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5170\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:04:16\n",
      "INFO:tensorflow:Saving dict for global step 5170: global_step = 5170, loss = 0.0427811\n",
      "Training epoch 26\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5170\n",
      "INFO:tensorflow:Saving checkpoints for 5171 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.016988, step = 5171\n",
      "INFO:tensorflow:Saving checkpoints for 5193 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0053621.\n",
      "Evaluating epoch 26\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:04:36\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5193\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:04:38\n",
      "INFO:tensorflow:Saving dict for global step 5193: global_step = 5193, loss = 0.0540571\n",
      "Training epoch 27\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5193\n",
      "INFO:tensorflow:Saving checkpoints for 5194 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0147958, step = 5194\n",
      "INFO:tensorflow:Saving checkpoints for 5216 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00329425.\n",
      "Evaluating epoch 27\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:05:03\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5216\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:05:05\n",
      "INFO:tensorflow:Saving dict for global step 5216: global_step = 5216, loss = 0.065242\n",
      "Training epoch 28\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5216\n",
      "INFO:tensorflow:Saving checkpoints for 5217 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.011222, step = 5217\n",
      "INFO:tensorflow:Saving checkpoints for 5239 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0027373.\n",
      "Evaluating epoch 28\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:05:26\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5239\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:05:27\n",
      "INFO:tensorflow:Saving dict for global step 5239: global_step = 5239, loss = 0.0493662\n",
      "Training epoch 29\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5239\n",
      "INFO:tensorflow:Saving checkpoints for 5240 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0114437, step = 5240\n",
      "INFO:tensorflow:Saving checkpoints for 5262 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00566679.\n",
      "Evaluating epoch 29\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:05:45\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5262\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:05:46\n",
      "INFO:tensorflow:Saving dict for global step 5262: global_step = 5262, loss = 0.0452581\n",
      "Training epoch 30\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5262\n",
      "INFO:tensorflow:Saving checkpoints for 5263 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.004293, step = 5263\n",
      "INFO:tensorflow:Saving checkpoints for 5285 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.23305e-05.\n",
      "Evaluating epoch 30\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:06:06\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5285\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:06:07\n",
      "INFO:tensorflow:Saving dict for global step 5285: global_step = 5285, loss = 0.048075\n",
      "Training epoch 31\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5285\n",
      "INFO:tensorflow:Saving checkpoints for 5286 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00350681, step = 5286\n",
      "INFO:tensorflow:Saving checkpoints for 5308 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000131556.\n",
      "Evaluating epoch 31\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:06:27\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5308\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:06:32\n",
      "INFO:tensorflow:Saving dict for global step 5308: global_step = 5308, loss = 0.0541333\n",
      "Training epoch 32\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5308\n",
      "INFO:tensorflow:Saving checkpoints for 5309 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00240875, step = 5309\n",
      "INFO:tensorflow:Saving checkpoints for 5331 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000616347.\n",
      "Evaluating epoch 32\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:06:52\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5331\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:06:53\n",
      "INFO:tensorflow:Saving dict for global step 5331: global_step = 5331, loss = 0.0497816\n",
      "Training epoch 33\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5331\n",
      "INFO:tensorflow:Saving checkpoints for 5332 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00143249, step = 5332\n",
      "INFO:tensorflow:Saving checkpoints for 5354 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000218462.\n",
      "Evaluating epoch 33\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:07:19\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5354\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:07:20\n",
      "INFO:tensorflow:Saving dict for global step 5354: global_step = 5354, loss = 0.0441356\n",
      "Training epoch 34\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5354\n",
      "INFO:tensorflow:Saving checkpoints for 5355 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00169639, step = 5355\n",
      "INFO:tensorflow:Saving checkpoints for 5377 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000633389.\n",
      "Evaluating epoch 34\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:07:41\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5377\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:07:42\n",
      "INFO:tensorflow:Saving dict for global step 5377: global_step = 5377, loss = 0.0393882\n",
      "Training epoch 35\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5377\n",
      "INFO:tensorflow:Saving checkpoints for 5378 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0023315, step = 5378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5400 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000612075.\n",
      "Evaluating epoch 35\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:08:08\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5400\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:08:09\n",
      "INFO:tensorflow:Saving dict for global step 5400: global_step = 5400, loss = 0.0403995\n",
      "Training epoch 36\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5400\n",
      "INFO:tensorflow:Saving checkpoints for 5401 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00207411, step = 5401\n",
      "INFO:tensorflow:Saving checkpoints for 5423 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00148978.\n",
      "Evaluating epoch 36\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:08:26\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5423\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:08:27\n",
      "INFO:tensorflow:Saving dict for global step 5423: global_step = 5423, loss = 0.0457881\n",
      "Training epoch 37\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5423\n",
      "INFO:tensorflow:Saving checkpoints for 5424 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00178458, step = 5424\n",
      "INFO:tensorflow:Saving checkpoints for 5446 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000911837.\n",
      "Evaluating epoch 37\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:08:49\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5446\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:08:52\n",
      "INFO:tensorflow:Saving dict for global step 5446: global_step = 5446, loss = 0.0571171\n",
      "Training epoch 38\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5446\n",
      "INFO:tensorflow:Saving checkpoints for 5447 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00482645, step = 5447\n",
      "INFO:tensorflow:Saving checkpoints for 5469 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000492999.\n",
      "Evaluating epoch 38\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:09:16\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5469\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:09:17\n",
      "INFO:tensorflow:Saving dict for global step 5469: global_step = 5469, loss = 0.064306\n",
      "Training epoch 39\n",
      "--------------------\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5469\n",
      "INFO:tensorflow:Saving checkpoints for 5470 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00446167, step = 5470\n",
      "INFO:tensorflow:Saving checkpoints for 5492 into colorbot/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00174196.\n",
      "Evaluating epoch 39\n",
      "--------------------\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:09:41\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5492\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:09:42\n",
      "INFO:tensorflow:Saving dict for global step 5492: global_step = 5492, loss = 0.0546852\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 40\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print('Training epoch %d' % i)\n",
    "    print('-' * 20)\n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "    print('Evaluating epoch %d' % i)\n",
    "    print('-' * 20)\n",
    "    estimator.evaluate(input_fn = test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To making prediction\n",
    "\n",
    "def predict(estimator, input_file):\n",
    "    preds = estimator.predict(input_fn=get_input_fn(input_file, 1, shuffle=False))\n",
    "    color_names = _get_csv_column(input_file, 'name')\n",
    "\n",
    "    print()\n",
    "    for p, name in zip(preds, color_names):\n",
    "        color = tuple(map(int, p * 255))\n",
    "        print(name + ',', 'rgb:', color)\n",
    "        _plot_rgb(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from colorbot/model.ckpt-5492\n",
      "orange, rgb: (238, 135, 45)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHERLwUG0FBxES+H//3GkeTfI8kYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1646fd208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow orange, rgb: (231, 135, 67)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS8FBtBQcREvBQbQUHERL4X/UhaSC2l8DFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164f91908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfgasdgasd, rgb: (96, 124, 105)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDqKl4CBaCg6ipeAgWgoOoqXwP5RvpDazPtRDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164e94eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple blue, rgb: (79, 58, 217)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJaCg2gpOIiWgoNoKTiIlsJ/ATy6pEjVIpwFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164c0d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple red, rgb: (183, 39, 90)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKTiIloKDaCk4iJaCg2gp/A9LPqQuRyqqhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x165435f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple, rgb: (128, 18, 143)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLQUH0VJwEC0FB9FS+B+88qQeUpUV6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1654b57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water, rgb: (200, 185, 170)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwUG0FBxES8FBtBQcREvhf2VmqZQNcBLXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164e9af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink, rgb: (247, 189, 227)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4CBaCg6ipeAgWgoOoqXwP7VkqdDigdOiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1655bbe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock, rgb: (97, 111, 109)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQbQUHERLwUG0FBxES+F/WF2kMxi7svkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16563a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predict(estimator, MY_TEST_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from pretrained/model.ckpt-8069\n",
      "orange, rgb: (233, 124, 19)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLQUH0VL4H5CopFvIxt8+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1661fc358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow orange, rgb: (232, 149, 88)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEC0FB9FScBAtBQfRUnAQLYX/AbySpJzh9ET4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1664d3b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfgasdgasd, rgb: (201, 184, 157)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noqXgIFoKDqKl4CBaCv8DqU2pjf9J6sEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1662f9710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple blue, rgb: (51, 13, 220)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16637a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple red, rgb: (152, 40, 61)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB5FJREFUeJzt3WGIHGcdx/Hvz+RqxETaJJikSWtaCEJEpeUsoS0YNYo5\nxVTwRau2USxHoJUKgkYDfSOI9YWUgrWEKqYo9E1rG8oVTaJFpKQ0bZPWWNOkGtB4bbBI2iBijv59\nMZOwXG5v927mZv/O/j6w3DM7z+7zDPdj54a5/z6KCMwG7R2DnoAZOIiWhINoKTiIloKDaCk4iJaC\ng2gpOIiWgoNoKSwe9ARms3TxSKwYWTLoaVif3jj3H85OndN8Xps6iCtGlvDd9dcMehrWp++ffGHe\nr/Wp2VJwEC0FB9FScBAtBQfRUnAQLYVKQZS0XNI+ScfLn5fN0neRpBckPVFlTGunqp+IO4EDEbEB\nOFBud3MX8HLF8aylqgZxG7CnbO8Bbpqpk6R1wGeAByuOZy1VNYirImKybL8GrOrS717gW8Dbvd5Q\n0rikQ5IOnZ06V3F69v+i5y0+SfuB1TPs2tW5EREh6aKSQEmfBU5HxHOSNvcaLyJ2A7sB3veuZS4x\nHBI9gxgRW7rtk/S6pDURMSlpDXB6hm43AJ+TNAYsAd4j6RcR8eV5z9pap+qpeS+wvWxvBx6f3iEi\nvhMR6yJiPXAz8FuH0KarGsQfAJ+UdBzYUm4j6XJJE1UnZ8Oj0r+BRcQbwCdmeP4fwNgMzz8FPFVl\nTGsn31mxFBxES8FBtBQcREvBQbQUHERLwUG0FBxES8FBtBQcREvBQbQUHERLYcGLpyRdIel3kv4k\n6aiku6qMae3URPHUFPDNiNgIbALukLSx4rjWMgtePBURkxHxfNl+i6KSb23Fca1lmiqeAkDSeuAa\n4JmK41rLLHjxVMf7LAUeAb4REW/O0m8cGAdYvvidvaZnLdFE8RSSRihC+MuIeLTHeK7iG0ILXjwl\nScBPgZcj4kcVx7OWaqJ46gbgVuDjkg6Xj4vqWWy4LXjxVET8AZjXF3zb8PCdFUvBQbQUHERLwUG0\nFBxES8FBtBQcREvBQbQUHERLwUG0FBxES8FBtBQcREuhliBK+rSkY5JOSLqogEqF+8r9L0q6to5x\nrT0qB1HSIuDHwFZgI3DLDFV6W4EN5WMc+EnVca1d6vhEvA44ERF/iYj/Ag9TVPd12gY8FIWDwKVl\naYEZUE8Q1wJ/69j+OxeXi/bTB/ASaMMq3cVKROyOiNGIGF26eGTQ07GG1BHEU8AVHdvryufm2seG\nWB1BfBbYIOkqSZdQLHO2d1qfvcBt5dXzJuBMR2G+WbXiKYCImJJ0J/BrYBHws4g4KmlHuf8BYIKi\nmOoE8G/gq1XHtXapHESAiJigCFvncw90tAO4o46xrJ3SXazYcHIQLQUH0VJwEC0FB9FScBAtBQfR\nUnAQLQUH0VJwEC0FB9FScBAtBQfRUmiqiu9LZfXeS5KelvThOsa19miqiu+vwEcj4oPA9yjXUTE7\nr5Eqvoh4OiL+VW4epCgVMLugqSq+Tl8Dnuy201V8w6mW/9Dul6SPUQTxxm59vATacKojiH1V6En6\nEPAgsLVcKMjsgkaq+CRdCTwK3BoRr9QwprVMU1V8dwMrgPuLNSKZiojRqmNbezRVxXc7cHsdY1k7\n+c6KpeAgWgoOoqXgIFoKDqKl4CBaCg6ipeAgWgoOoqXgIFoKDqKl4CBaCg6ipdBIFV9Hv49ImpL0\nhTrGtfZoqorvfL97gN9UHdPap6m1+AC+DjwCnK5hTGuZRqr4JK0FPk8fq5K6im84NXWxci/w7Yh4\nu1dHr8U3nJqq4hsFHi7rVVYCY5KmIuKxGsa3FqgjiBeq+CgCeDPwxc4OEXHV+baknwNPOITWqakq\nPrNZNVLFN+35r9QxprWL76xYCg6ipeAgWgoOoqXgIFoKKhaXz0nSW8CxQc9jAawE/jnoSSyA90fE\nsvm8sNEv6pyHY2381jBJh9p6XPN9rU/NloKDaClkD2Jbl8HwcU2T+mLFhkf2T0QbEmmCKGm5pH2S\njpc/L+vS72S5lNrhKldpTehjaThJuq/c/6Kkawcxz7nq47g2SzpT/o4OS7q755tGRIoH8ENgZ9ne\nCdzTpd9JYOWg59vH8SwCXgWuBi4BjgAbp/UZo1j8SMAm4JlBz7um49pM8T+nfb9vmk9EioKrPWV7\nD3DTAOdSh36KyrYBD0XhIHCppDVNT3SO+i2Wm5NMQVwVEZNl+zVgVZd+AeyX9Jyk8WamNi/9LA03\n1+XjMuh3zteXf248KekDvd606SXQ9gOrZ9i1q3MjIkJSt8v5GyPilKT3Avsk/Tkifl/3XK2S54Er\nI+KspDHgMWDDbC9oNIgRsaXbPkmvS1oTEZPl6WnG+ueIOFX+PC3pVxSnioxB7KeorK/l45LpOeeI\neLOjPSHpfkkrI6Lr/fVMp+a9wPayvR14fHoHSe+WtOx8G/gU8MfGZjg3PZeGK7dvK6+eNwFnOv48\nyaqfJe9WqyzZlHQdRc5mX39x0FdhHVdaK4ADwHFgP7C8fP5yYKJsX01xlXYEOArsGvS8exzTGPAK\nxVXmrvK5HcCOsi2Kr2t5FXgJGB30nGs6rjvL388RivW5r+/1nr6zYilkOjXbEHMQLQUH0VJwEC0F\nB9FScBAtBQfRUnAQLYX/AROOpAaBXtQiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16633b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple, rgb: (92, 23, 109)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1663b56d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water, rgb: (160, 201, 202)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWgoOoqXgIFoK/wPqRamYgvM6iwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1665f4b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink, rgb: (257, 153, 165)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB9FS+B+p9p82x6S0bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x166682ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock, rgb: (83, 65, 52)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAACPCAYAAAB5wADzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAB5xJREFUeJzt3VGIXGcZxvH/Y+pubGxo0mCSJi1tIQgRFctaQlswmihm\nFVPBi1ZtowhLoJUKgkYCvfHGeiGlYC2hiikKvWltQ9miyWoRKSlu26Q1qWlSLWjcNiglqRYTlr5e\nnJMwbnZ2ZvfMnnl75vnBst8555v5vmEf5uzZs+98igjM+u09/Z6AGTiIloSDaCk4iJaCg2gpOIiW\ngoNoKTiIloKDaClc0u8JzGV46JK4dOlwv6dhXXr7v2c5e25aC3ls6iBeunSYLSMb+z0N69LE5NEF\nP9anZkvBQbQUHERLwUG0FBxES8FBtBQqBVHSSkn7JR0vv6+Yo+8SSS9IerLKmNZMVd8RdwETEbEB\nmCi327kbeLnieNZQVYO4HdhbtvcCt8zWSdJ64HPAQxXHs4aqGsTVETFVtl8HVrfpdx/wHeCdTk8o\naUzSpKTJs+emK07P3i063uKTdABYM8uh3a0bERGSLioJlPR54FREPCdpc6fxImIPsAdgxfJlLjEc\nEB2DGBFb2x2T9IaktRExJWktcGqWbjcBX5A0CiwFlkv6RUR8dcGztsapemreB+wo2zuAJ2Z2iIjv\nRcT6iLgGuBX4rUNoM1UN4g+AT0s6Dmwtt5F0paTxqpOzwVHp38Ai4l/Alln2/wMYnWX/08DTVca0\nZvKdFUvBQbQUHERLwUG0FBxES8FBtBQcREvBQbQUHERLwUG0FBxES8FBtBQWvXhK0lWSfifpqKQj\nku6uMqY1Ux3FU9PAtyNiI7AJuFOSP1nJ/s+iF09FxFREPF+236Ko5FtXcVxrmLqKpwCQdA3wMeDZ\niuNawyx68VTL87wfeBT4VkScmaPfGDAG8L7hoU7Ts4aoo3gKSe+lCOEvI+KxDuO5im8ALXrxlCQB\nPwVejogfVRzPGqqO4qmbgNuBT0k6VH5dVM9ig23Ri6ci4g/Agj7g2waH76xYCg6ipeAgWgoOoqXg\nIFoKDqKl4CBaCg6ipeAgWgoOoqXgIFoKDqKl4CBaCj0JoqTPSjom6YSkiwqoVLi/PP6ipOt7Ma41\nR+UgSloC/BjYBmwEbpulSm8bsKH8GgN+UnVca5ZevCPeAJyIiL9ExDngEYrqvlbbgYejcBC4vCwt\nMAN6E8R1wN9atv/OxeWi3fQBvATaoEp3sRIReyJiJCJGhocq/QO5vYv0IogngatatteX++bbxwZY\nL4L4R2CDpGslDVEsc7ZvRp99wB3l1fMm4HRLYb5ZteIpgIiYlnQX8GtgCfCziDgiaWd5/EFgnKKY\n6gTwNvD1quNas/Tkl7CIGKcIW+u+B1vaAdzZi7GsmdJdrNhgchAtBQfRUnAQLQUH0VJwEC0FB9FS\ncBAtBQfRUnAQLQUH0VJwEC0FB9FSqKuK7ytl9d5Lkp6R9NFejGvNUVcV31+BT0TEh4HvU66jYnZe\nLVV8EfFMRLxZbh6kKBUwu6CuKr5W3wCeanfQVXyDqdYyOUmfpAjize36eAm0wdSLIHZVoSfpI8BD\nwLZyoSCzC2qp4pN0NfAYcHtEvNKDMa1h6qriuwe4AnigWCOS6YgYqTq2NYeKArucVixfFltGZv4l\nyLKamDzKm2f+s6B1F31nxVJwEC0FB9FScBAtBQfRUnAQLQUH0VJwEC0FB9FScBAtBQfRUnAQLQUH\n0VKopYqvpd/HJU1L+lIvxrXmqKuK73y/e4HfVB3TmqeutfgAvgk8CpzqwZjWMLVU8UlaB3yRLlYl\ndRXfYKrrYuU+4LsR8U6njl6LbzDVVcU3AjxS1qusAkYlTUfE4z0Y3xqgF0G8UMVHEcBbgS+3doiI\na8+3Jf0ceNIhtFZ1VfGZzamWtfhm7P9aL8a0ZvGdFUvBQbQUHERLwUG0FBxESyH1Z99Iegs41u95\nLIJVwD/7PYlF8MGIuGwhD8x+D+1YEz81TNJkU1/XQh/rU7Ol4CBaCtmD2NRlMPy6Zkh9sWKDI/s7\nog2INEGUtFLSfknHy+8r2vR7rVxK7VCVq7Q6dLE0nCTdXx5/UdL1/ZjnfHXxujZLOl3+jA5Juqfj\nk0ZEii/gh8Cusr0LuLdNv9eAVf2ebxevZwnwKnAdMAQcBjbO6DNKsfiRgE3As/2ed49e12aK/znt\n+nnTvCNSFFztLdt7gVv6OJde6KaobDvwcBQOApdLWlv3ROep22K5eckUxNURMVW2XwdWt+kXwAFJ\nz0kaq2dqC9LN0nDzXT4ug27nfGP568ZTkj7U6UnrXgLtALBmlkO7WzciIiS1u5y/OSJOSvoAsF/S\nnyPi972eq1XyPHB1RPxb0ijwOLBhrgfUGsSI2NrumKQ3JK2NiKny9DRr/XNEnCy/n5L0K4pTRcYg\ndlNU1tXyccl0nHNEnGlpj0t6QNKqiGh7fz3TqXkfsKNs7wCemNlB0jJJl51vA58B/lTbDOen49Jw\n5fYd5dXzJuB0y68nWXWz5N0alSWbkm6gyNnc6y/2+yqs5UrrCmACOA4cAFaW+68Exsv2dRRXaYeB\nI8Dufs+7w2saBV6huMrcXe7bCews26L4uJZXgZeAkX7PuUev667y53OYYn3uGzs9p++sWAqZTs02\nwBxES8FBtBQcREvBQbQUHERLwUG0FBxES+F/QNyiFvUsx0QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1666fcda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pre-train model prediction\n",
    "\n",
    "pre_estimator = tf.estimator.Estimator(model_dir='pretrained', model_fn=model_fn)\n",
    "predict(pre_estimator, MY_TEST_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1234a3eb8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'model_dir'}\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /Users/taocheng/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taocheng/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from model_dir/model.ckpt-732\n",
      "INFO:tensorflow:Saving checkpoints for 733 into model_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00526277, step = 733\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:14:36\n",
      "INFO:tensorflow:Restoring parameters from model_dir/model.ckpt-733\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:14:37\n",
      "INFO:tensorflow:Saving dict for global step 733: global_step = 733, loss = 0.0967104\n",
      "INFO:tensorflow:Validation (step 733): loss = 0.0967104, global_step = 733\n",
      "INFO:tensorflow:global_step/sec: 3.56024\n",
      "INFO:tensorflow:loss = 0.0172557, step = 833 (28.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.15839\n",
      "INFO:tensorflow:loss = 0.00393331, step = 933 (24.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.02317\n",
      "INFO:tensorflow:loss = 0.00223359, step = 1033 (19.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.55635\n",
      "INFO:tensorflow:loss = 0.0105142, step = 1133 (17.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.15509\n",
      "INFO:tensorflow:loss = 0.0030129, step = 1233 (19.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.21625\n",
      "INFO:tensorflow:loss = 0.000902587, step = 1333 (19.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.89851\n",
      "INFO:tensorflow:loss = 0.000904116, step = 1433 (20.415 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1464 into model_dir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000443131.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-15-18:17:18\n",
      "INFO:tensorflow:Restoring parameters from model_dir/model.ckpt-1464\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-15-18:17:19\n",
      "INFO:tensorflow:Saving dict for global step 1464: global_step = 1464, loss = 0.0879452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 1464, 'loss': 0.087945201}, [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small important detail, to train properly with the experiment you need to\n",
    "# repeat the dataset the number of epochs desired\n",
    "train_input_fn = get_input_fn(TRAIN_INPUT, BATCH_SIZE, num_epochs=40)\n",
    "\n",
    "# create experiment\n",
    "def generate_experiment_fn(run_config, hparams):\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=test_input_fn\n",
    "    )\n",
    "\n",
    "learn_runner.run(generate_experiment_fn, run_config=tf.contrib.learn.RunConfig(model_dir='model_dir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_fn(csv_file, batch_size, num_epochs=1, shuffle=True):\n",
    "    def _parse(line):\n",
    "        # each line: name, red, green, blue\n",
    "        # split line\n",
    "        items = tf.string_split([line],',').values\n",
    "\n",
    "        # get color (r, g, b)\n",
    "        color = tf.string_to_number(items[1:], out_type=tf.float32) / 255.0\n",
    "\n",
    "        # split color_name into a sequence of characters\n",
    "        color_name = tf.string_split([items[0]], '')\n",
    "        length = color_name.indices[-1, 1] + 1 # length = index of last char + 1\n",
    "        color_name = color_name.values\n",
    "        return color, color_name, length\n",
    "\n",
    "    def input_fn():\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "        dataset = (\n",
    "            tf.contrib.data.TextLineDataset(csv_file) # reading from the HD\n",
    "            .skip(1) # skip header\n",
    "            .map(_parse) # parse text to variables\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], []),\n",
    "                               padding_values=(0.0, chr(0), tf.cast(0, tf.int64)))\n",
    "            \n",
    "            .repeat(num_epochs) # repeat dataset the number of epochs\n",
    "        )\n",
    "        \n",
    "        # for our \"manual\" test we don't want to shuffle the data\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=100000)\n",
    "\n",
    "        # create iterator\n",
    "        color, color_name, length = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "        features = {\n",
    "            COLOR_NAME_KEY: color_name,\n",
    "            SEQUENCE_LENGTH_KEY: length,\n",
    "        }\n",
    "\n",
    "        return features, color\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_fn(rnn_cell_sizes,\n",
    "                 label_dimension,\n",
    "                 dnn_layer_sizes=[],\n",
    "                 optimizer='SGD',\n",
    "                 learning_rate=0.01):\n",
    "    \n",
    "    def model_fn(features, labels, mode):\n",
    "        \n",
    "        color_name = features[COLOR_NAME_KEY]\n",
    "        sequence_length = tf.cast(features[SEQUENCE_LENGTH_KEY], dtype=tf.int32) # int64 -> int32\n",
    "        \n",
    "        # ----------- Preparing input --------------------\n",
    "        # Creating a tf constant to hold the map char -> index\n",
    "        # this is need to create the sparse tensor and after the one hot encode\n",
    "        mapping = tf.constant(CHARACTERS, name=\"mapping\")\n",
    "        table = tf.contrib.lookup.index_table_from_tensor(mapping, dtype=tf.string)\n",
    "        int_color_name = table.lookup(color_name)\n",
    "        \n",
    "        # representing colornames with one hot representation\n",
    "        color_name_onehot = tf.one_hot(int_color_name, depth=len(CHARACTERS) + 1)\n",
    "        \n",
    "        # ---------- RNN -------------------\n",
    "        # Each RNN layer will consist of a GRU cell\n",
    "        rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in rnn_cell_sizes]\n",
    "        \n",
    "        # Construct the layers\n",
    "        multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        # Runs the RNN model dynamically\n",
    "        # more about it at: \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                                 inputs=color_name_onehot,\n",
    "                                                 sequence_length=sequence_length,\n",
    "                                                 dtype=tf.float32)\n",
    "\n",
    "        # Slice to keep only the last cell of the RNN\n",
    "        last_activations = rnn_common.select_last_activations(outputs,\n",
    "                                                              sequence_length)\n",
    "\n",
    "        # ------------ Dense layers -------------------\n",
    "        # Construct dense layers on top of the last cell of the RNN\n",
    "        for units in dnn_layer_sizes:\n",
    "            last_activations = tf.layers.dense(\n",
    "              last_activations, units, activation=tf.nn.relu)\n",
    "        \n",
    "        # Final dense layer for prediction\n",
    "        predictions = tf.layers.dense(last_activations, label_dimension)\n",
    "\n",
    "        # ----------- Loss and Optimizer ----------------\n",
    "        loss = None\n",
    "        train_op = None\n",
    "\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:    \n",
    "            loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:    \n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "              loss,\n",
    "              tf.contrib.framework.get_global_step(),\n",
    "              optimizer=optimizer,\n",
    "              learning_rate=learning_rate)\n",
    "        \n",
    "        return model_fn_lib.EstimatorSpec(mode,\n",
    "                                           predictions=predictions,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train_op)\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
